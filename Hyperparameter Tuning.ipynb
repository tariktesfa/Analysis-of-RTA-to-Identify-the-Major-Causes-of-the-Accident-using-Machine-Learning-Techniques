{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result\n",
    " Based on the result that I got by training the model with the seven algorithms with normal distribution of the \n",
    " classes(Baseline model), undersampling and SMOTE oversampling Techniques, we can show that the accuracy and F1 score of the Models are \n",
    " higher that that of normal distributions of the classes and undersampling technique except Naive Bayesian algorithm.\n",
    " Random Forest is having the higher score and optimistic result than other algorithms so we'll implement hyperparameter tuning to check wether we can optimize the score of the model or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.offline as py\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score,roc_curve,f1_score,recall_score,precision_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import time             \n",
    "import plotly.offline as py\n",
    "from plotly import tools\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For ignoring warnings to view clean output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the dataset\n",
    "data = pd.read_csv('Data/cleaned.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separating Independent and Dependent features\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "#### Handling Categorical Variables - Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_band_of_driver : 5 categories\n",
      "Sex_of_driver : 3 categories\n",
      "Educational_level : 7 categories\n",
      "Vehicle_driver_relation : 4 categories\n",
      "Driving_experience : 8 categories\n",
      "Lanes_or_Medians : 7 categories\n",
      "Types_of_Junction : 8 categories\n",
      "Road_surface_type : 6 categories\n",
      "Light_conditions : 4 categories\n",
      "Weather_conditions : 9 categories\n",
      "Type_of_collision : 10 categories\n",
      "Vehicle_movement : 13 categories\n",
      "Pedestrian_movement : 9 categories\n",
      "Cause_of_accident : 20 categories\n",
      "Accident_severity : 3 categories\n"
     ]
    }
   ],
   "source": [
    "# Shows the columns with their number of categories each variable is having\n",
    "for col in data.columns:\n",
    "    print(col, ':', len(data[col].unique()), 'categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12316, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data,drop_first=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12316, 99)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the dataset:  0.0\n",
      "Standard deviation of the dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of the dataset: \", np.mean(X).round(8))\n",
    "print(\"Standard deviation of the dataset: \", np.std(X).round(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10415\n",
       "1     1743\n",
       "0      158\n",
       "Name: Accident_severity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking for data imbalance \n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slight Injury: 84.56%\n",
      "Serious Injury: 14.15%\n",
      "Fatal Injury: 1.28%\n"
     ]
    }
   ],
   "source": [
    "print('Slight Injury: ' + str(round(data['Accident_severity'].value_counts()[2] / len(data) * 100, 2)) + '%\\nSerious Injury: ' + \n",
    "      str(round(data['Accident_severity'].value_counts()[1] / len(data) * 100, 2))  + '%\\nFatal Injury: ' + \n",
    "      str(round(data['Accident_severity'].value_counts()[0] / len(data) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE Oversampling Techniques for handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "sm = SMOTE(random_state=0)\n",
    "X_over, y_over = sm.fit_sample(X, y)\n",
    "## train test split\n",
    "X_train_over,X_test_over,y_train_over,y_test_over = train_test_split(X_over,y_over,test_size=0.2,random_state=42)\n",
    "#setting 20% aside as validation data for cross validation\n",
    "x_train_t, x_train_v, y_train_t, y_train_v = train_test_split(X_train_over, y_train_over, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10415\n",
       "1    10415\n",
       "0    10415\n",
       "Name: Accident_severity, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print class frequencies \n",
    "pd.Series(y_over).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24996, 99)\n",
      "(6249, 99)\n",
      "(24996,)\n",
      "(6249,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of our training and test set \n",
    "print(X_train_over.shape)\n",
    "print(X_test_over.shape)\n",
    "print(y_train_over.shape)\n",
    "print(y_test_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2100\n",
       "0    2085\n",
       "2    2064\n",
       "Name: Accident_severity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_over.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Without Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 5.987990617752075 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "RF_model = RandomForestClassifier()\n",
    "# feeding the training data into the model\n",
    "RF_model.fit(X_train_over, y_train_over)\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: - \n",
      " [[2057    2   26]\n",
      " [   6 1727  367]\n",
      " [   1   42 2021]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       1.00      0.99      0.99      2085\n",
      "     Serious       0.98      0.82      0.89      2100\n",
      "      Slight       0.84      0.98      0.90      2064\n",
      "\n",
      "    accuracy                           0.93      6249\n",
      "   macro avg       0.94      0.93      0.93      6249\n",
      "weighted avg       0.94      0.93      0.93      6249\n",
      "\n",
      "Recall: 0.9293727874842982\n",
      "Precision: 0.9363211584115742\n",
      "F1 score: 0.9288250783345221\n"
     ]
    }
   ],
   "source": [
    "# predicting the values for x-test\n",
    "y_pred = RF_model.predict(X_test_over)\n",
    "# finding the training and testing accuracy\n",
    "name = ['Fatal','Serious','Slight']\n",
    "RF_r=recall_score(y_test_over,y_pred, average='macro')\n",
    "RF_p=precision_score(y_test_over,y_pred, average='macro')\n",
    "RF_f=f1_score(y_test_over,y_pred, average='macro')\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test_over, y_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test_over, y_pred,target_names=name))\n",
    "print(\"Recall:\", RF_r)\n",
    "print(\"Precision:\", RF_p)\n",
    "print(\"F1 score:\", RF_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation : F1 Macro\n",
    "**In this problem domain all classes should be treated equally. So Macro F1-score will give the same importance to each label/\n",
    "class. It will be low for models that only perform well on the common classes while performing poorly on the rare classes.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 90.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 147.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 214.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 309.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 418.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 562.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 718.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 884.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 1006.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 1157.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 1807.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 2087.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 2391.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 2496.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 149796.46750068665 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Setting values for the parameters\n",
    "n_estimators = [100, 300, 500, 800, 1000]\n",
    "criterion = ['gini','entropy']\n",
    "max_depth = [5, 10, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "max_features = ['auto','log2','sqrt']\n",
    "\n",
    "#Creating a dictionary for the hyper parameters\n",
    "parameters = dict(n_estimators = n_estimators, criterion =criterion, max_depth = max_depth, \n",
    "              min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_features = max_features)\n",
    "cv = KFold(n_splits= 5, shuffle=False, random_state=42)\n",
    "RF_model = RandomForestClassifier()\n",
    "grid_RF_model = GridSearchCV(RF_model, parameters, cv = cv, scoring='f1_macro', verbose = 1, n_jobs = -1)\n",
    "\n",
    "# feeding the training data into the model\n",
    "best_RF= grid_RF_model.fit(X_train_over, y_train_over)\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper parameters are:\n",
      " {'criterion': 'gini', 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#Printing the best hyperparameters\n",
    "print('The best hyper parameters are:\\n',grid_RF_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 22.996673345565796 sec\n"
     ]
    }
   ],
   "source": [
    "#Fitting the random forest model with the best hyper parameters obtained through GridSearchCV\n",
    "start_time = time.time()\n",
    "RF_model = RandomForestClassifier(criterion ='gini',max_depth=30,max_features='log2',min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "RF_model.fit(X_train_over,y_train_over)\n",
    "y_pred_h = RF_model.predict(X_test_over)\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: - \n",
      " [[2058    1   26]\n",
      " [   7 1718  375]\n",
      " [   0   14 2050]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       1.00      0.99      0.99      2085\n",
      "     Serious       0.99      0.82      0.90      2100\n",
      "      Slight       0.84      0.99      0.91      2064\n",
      "\n",
      "    accuracy                           0.93      6249\n",
      "   macro avg       0.94      0.93      0.93      6249\n",
      "weighted avg       0.94      0.93      0.93      6249\n",
      "\n",
      "Recall: 0.9327875506903448\n",
      "Precision: 0.9414493225566417\n",
      "F1 score: 0.9321057229894095\n"
     ]
    }
   ],
   "source": [
    "## print the evaluation metrics results\n",
    "name = ['Fatal','Serious','Slight']\n",
    "RF_r=recall_score(y_test_over,y_pred_h, average='macro')\n",
    "RF_p=precision_score(y_test_over,y_pred_h, average='macro')\n",
    "RF_f=f1_score(y_test_over,y_pred_h, average='macro')\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test_over, y_pred_h))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test_over, y_pred_h,target_names=name))\n",
    "print(\"Recall:\", RF_r)\n",
    "print(\"Precision:\", RF_p)\n",
    "print(\"F1 score:\", RF_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observtaions & Conclusions:\n",
    "After hyperparameter tuning the performance of the model has increased to a certain extent against the one when we used default hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
